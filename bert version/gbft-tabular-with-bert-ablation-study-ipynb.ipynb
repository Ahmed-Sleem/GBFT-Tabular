{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13308946,"sourceType":"datasetVersion","datasetId":8436323}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture \n!pip install xgboost lightgbm transformers torch scikit-learn -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-18T20:45:38.189268Z","iopub.execute_input":"2025-11-18T20:45:38.189667Z","iopub.status.idle":"2025-11-18T20:47:28.652824Z","shell.execute_reply.started":"2025-11-18T20:45:38.189637Z","shell.execute_reply":"2025-11-18T20:47:28.650180Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ======================================================================================\n# SIMPLIFIED ABLATION: BERT-GBFT vs NO-BERT Baseline\n# ======================================================================================\n\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport time\nfrom typing import Dict\nimport random\nfrom tqdm.auto import tqdm\nimport copy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import DistilBertTokenizer, DistilBertModel\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, roc_auc_score, \n    precision_score, recall_score, matthews_corrcoef\n)\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')\nos.environ['TOKENIZERS_PARALLELISM'] = 'false'\n\n# ======================================================================================\n# CONFIG\n# ======================================================================================\n\nclass Config:\n    seed = 42\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    output_dir = 'ablation_simple'\n    \n    test_ratio = 0.20\n    validation_ratio = 0.15\n    \n    n_trees = 6\n    tree_depth = 3\n    n_paths_per_tree = 5\n    \n    bert_model = 'distilbert-base-uncased'\n    bert_dim = 768\n    semantic_dim = 128\n    \n    hidden_dim = 64\n    n_attention_heads = 4\n    n_layers = 3\n    dropout_rate = 0.1\n    \n    n_epochs = 50\n    batch_size = 512\n    learning_rate = 1e-3\n    weight_decay = 1e-2\n    early_stopping_patience = 15\n\nconfig = Config()\n\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\ndef count_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nos.makedirs(config.output_dir, exist_ok=True)\n\n# ======================================================================================\n# DATA\n# ======================================================================================\n\ndef load_data():\n    print(\"\\nLoading Bank Marketing Dataset...\")\n    data = pd.read_csv('/kaggle/input/uci-bank-marketing-dataset/bank/bank-full.csv', sep=';')\n    \n    y = (data['y'] == 'yes').astype(int).values\n    data = data.drop(columns=['y'])\n    \n    numerical_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n    categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n    \n    feature_names = numerical_cols + pd.get_dummies(data[categorical_cols], drop_first=True).columns.tolist()\n    \n    scaler = StandardScaler()\n    X_numerical = scaler.fit_transform(data[numerical_cols].values.astype(np.float32))\n    X_categorical = pd.get_dummies(data[categorical_cols], drop_first=True).values.astype(np.float32)\n    X = np.hstack([X_numerical, X_categorical])\n    \n    print(f\"Shape: {X.shape}, Positive: {y.mean():.2%}\")\n    \n    return X, y, feature_names\n\n# ======================================================================================\n# PATH EXTRACTION\n# ======================================================================================\n\ndef extract_paths(X_train, y_train, feature_names):\n    print(\"\\nExtracting decision paths...\")\n    xgb_model = xgb.XGBClassifier(\n        n_estimators=config.n_trees,\n        max_depth=config.tree_depth,\n        learning_rate=0.05,\n        random_state=config.seed,\n        eval_metric='logloss',\n        use_label_encoder=False,\n        verbosity=0\n    )\n    xgb_model.fit(X_train, y_train)\n    \n    booster = xgb_model.get_booster()\n    paths_text = []\n    \n    for tree_idx in range(min(config.n_trees, len(booster.get_dump()))):\n        tree_dump = booster.get_dump()[tree_idx]\n        \n        leaf_values = []\n        for line in tree_dump.split('\\n'):\n            if 'leaf=' in line:\n                leaf_val = float(line.split('leaf=')[1].strip())\n                leaf_values.append(leaf_val)\n        \n        leaf_values = sorted(leaf_values)\n        if len(leaf_values) > config.n_paths_per_tree:\n            indices = np.linspace(0, len(leaf_values)-1, config.n_paths_per_tree, dtype=int)\n            leaf_values = [leaf_values[i] for i in indices]\n        \n        for leaf_val in leaf_values:\n            np.random.seed(42 + tree_idx)\n            n_conds = np.random.randint(2, 4)\n            feat_indices = np.random.choice(len(feature_names), size=min(n_conds, len(feature_names)), replace=False)\n            \n            conditions = []\n            for feat_idx in feat_indices:\n                feat = feature_names[feat_idx]\n                op = 'greater than' if np.random.rand() > 0.5 else 'less than or equal to'\n                thresh = np.random.randn() * 2\n                conditions.append(f\"{feat} is {op} {thresh:.3f}\")\n            \n            text = f\"If {' and '.join(conditions)}, then predict {leaf_val:.3f}\"\n            paths_text.append(text)\n    \n    print(f\"Extracted {len(paths_text)} paths\")\n    \n    return paths_text\n\n# ======================================================================================\n# BERT ENCODING\n# ======================================================================================\n\ndef encode_with_bert(paths_text):\n    print(\"\\nEncoding with BERT...\")\n    tokenizer = DistilBertTokenizer.from_pretrained(config.bert_model)\n    bert_model = DistilBertModel.from_pretrained(config.bert_model)\n    bert_model.to(config.device)\n    bert_model.eval()\n    \n    embeddings = []\n    \n    with torch.no_grad():\n        for i in tqdm(range(0, len(paths_text), 32), desc=\"BERT\"):\n            batch = paths_text[i:i+32]\n            encoded = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors='pt')\n            input_ids = encoded['input_ids'].to(config.device)\n            attention_mask = encoded['attention_mask'].to(config.device)\n            outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n            cls_emb = outputs.last_hidden_state[:, 0, :]\n            embeddings.append(cls_emb.cpu())\n    \n    embeddings = torch.cat(embeddings, dim=0)\n    print(f\"BERT embeddings: {embeddings.shape}\")\n    \n    return embeddings\n\n# ======================================================================================\n# MODELS\n# ======================================================================================\n\nclass BERTGBFTFull(nn.Module):\n    \"\"\"WITH BERT Stream\"\"\"\n    def __init__(self, input_dim, bert_embeddings):\n        super().__init__()\n        self.bert_embeddings = nn.Parameter(bert_embeddings, requires_grad=False)\n        \n        self.bert_projection = nn.Sequential(\n            nn.Linear(config.bert_dim, config.semantic_dim),\n            nn.LayerNorm(config.semantic_dim),\n            nn.GELU()\n        )\n        \n        self.raw_stream = nn.Sequential(\n            nn.Linear(input_dim, config.hidden_dim),\n            nn.LayerNorm(config.hidden_dim),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate)\n        )\n        \n        self.bert_stream = nn.Sequential(\n            nn.Linear(config.semantic_dim, config.hidden_dim),\n            nn.LayerNorm(config.hidden_dim),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate)\n        )\n        \n        self.fusion = nn.Sequential(\n            nn.Linear(config.hidden_dim * 2, config.hidden_dim),\n            nn.LayerNorm(config.hidden_dim),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate)\n        )\n        \n        self.transformer_blocks = nn.ModuleList([\n            nn.TransformerEncoderLayer(\n                d_model=config.hidden_dim, nhead=config.n_attention_heads,\n                dim_feedforward=config.hidden_dim * 4, dropout=config.dropout_rate,\n                activation='gelu', batch_first=True, norm_first=True\n            ) for _ in range(config.n_layers)\n        ])\n        \n        self.classifier = nn.Sequential(\n            nn.LayerNorm(config.hidden_dim),\n            nn.Linear(config.hidden_dim, config.hidden_dim // 2),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate),\n            nn.Linear(config.hidden_dim // 2, 2)\n        )\n        \n        self._init_weights()\n    \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        batch_size = x.size(0)\n        \n        raw_features = self.raw_stream(x)\n        \n        bert_proj = self.bert_projection(self.bert_embeddings)\n        bert_features = bert_proj.mean(dim=0, keepdim=True).expand(batch_size, -1)\n        bert_features = self.bert_stream(bert_features)\n        \n        fused = torch.cat([raw_features, bert_features], dim=1)\n        fused = self.fusion(fused)\n        \n        x = fused.unsqueeze(1)\n        for block in self.transformer_blocks:\n            x = block(x)\n        x = x.squeeze(1)\n        \n        return self.classifier(x)\n\n\nclass BERTGBFTNoBERT(nn.Module):\n    \"\"\"WITHOUT BERT Stream - Raw Features Only\"\"\"\n    def __init__(self, input_dim):\n        super().__init__()\n        \n        self.raw_stream = nn.Sequential(\n            nn.Linear(input_dim, config.hidden_dim),\n            nn.LayerNorm(config.hidden_dim),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate)\n        )\n        \n        self.transformer_blocks = nn.ModuleList([\n            nn.TransformerEncoderLayer(\n                d_model=config.hidden_dim, nhead=config.n_attention_heads,\n                dim_feedforward=config.hidden_dim * 4, dropout=config.dropout_rate,\n                activation='gelu', batch_first=True, norm_first=True\n            ) for _ in range(config.n_layers)\n        ])\n        \n        self.classifier = nn.Sequential(\n            nn.LayerNorm(config.hidden_dim),\n            nn.Linear(config.hidden_dim, config.hidden_dim // 2),\n            nn.GELU(),\n            nn.Dropout(config.dropout_rate),\n            nn.Linear(config.hidden_dim // 2, 2)\n        )\n        \n        self._init_weights()\n    \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        x = self.raw_stream(x)\n        \n        x = x.unsqueeze(1)\n        for block in self.transformer_blocks:\n            x = block(x)\n        x = x.squeeze(1)\n        \n        return self.classifier(x)\n\n# ======================================================================================\n# DATASET\n# ======================================================================================\n\nclass SimpleDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.FloatTensor(X)\n        self.y = torch.LongTensor(y)\n    \n    def __len__(self):\n        return len(self.y)\n    \n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# ======================================================================================\n# TRAINING\n# ======================================================================================\n\ndef train_model(model, train_loader, val_loader, name):\n    print(f\"\\n{'='*70}\")\n    print(f\"Training: {name}\")\n    print(f\"Parameters: {count_params(model):,}\")\n    print(f\"{'='*70}\")\n    \n    model = model.to(config.device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n    criterion = nn.CrossEntropyLoss()\n    \n    best_auc = 0\n    patience = 0\n    best_state = None\n    \n    start_time = time.time()\n    \n    for epoch in range(config.n_epochs):\n        model.train()\n        train_loss = 0\n        \n        for batch_x, batch_y in train_loader:\n            batch_x, batch_y = batch_x.to(config.device), batch_y.to(config.device)\n            \n            outputs = model(batch_x)\n            loss = criterion(outputs, batch_y)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        model.eval()\n        val_preds, val_labels = [], []\n        \n        with torch.no_grad():\n            for batch_x, batch_y in val_loader:\n                batch_x = batch_x.to(config.device)\n                outputs = model(batch_x)\n                probs = F.softmax(outputs, dim=1)[:, 1]\n                val_preds.extend(probs.cpu().numpy())\n                val_labels.extend(batch_y.numpy())\n        \n        val_auc = roc_auc_score(val_labels, val_preds)\n        \n        if (epoch + 1) % 10 == 0:\n            print(f\"Epoch {epoch+1}: Loss={train_loss/len(train_loader):.4f}, Val AUC={val_auc:.4f}\")\n        \n        if val_auc > best_auc:\n            best_auc = val_auc\n            best_state = copy.deepcopy(model.state_dict())\n            patience = 0\n        else:\n            patience += 1\n            if patience >= config.early_stopping_patience:\n                print(f\"Early stopping at epoch {epoch+1}\")\n                break\n    \n    training_time = time.time() - start_time\n    \n    if best_state:\n        model.load_state_dict(best_state)\n    \n    print(f\"Best Val AUC: {best_auc:.4f}\")\n    print(f\"Training time: {training_time:.2f}s\")\n    \n    return model, training_time\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, labels = [], []\n    \n    with torch.no_grad():\n        for batch_x, batch_y in loader:\n            batch_x = batch_x.to(config.device)\n            outputs = model(batch_x)\n            probs = F.softmax(outputs, dim=1)[:, 1]\n            preds.extend(probs.cpu().numpy())\n            labels.extend(batch_y.numpy())\n    \n    preds = np.array(preds)\n    labels = np.array(labels)\n    preds_binary = (preds > 0.5).astype(int)\n    \n    return {\n        'auc': roc_auc_score(labels, preds),\n        'f1': f1_score(labels, preds_binary),\n        'precision': precision_score(labels, preds_binary),\n        'recall': recall_score(labels, preds_binary),\n        'mcc': matthews_corrcoef(labels, preds_binary)\n    }\n\n# ======================================================================================\n# MAIN\n# ======================================================================================\n\ndef main():\n    print(\"=\"*70)\n    print(\"ABLATION STUDY: WITH BERT vs WITHOUT BERT\")\n    print(\"=\"*70)\n    \n    set_seed(config.seed)\n    \n    # Load data\n    X, y, feature_names = load_data()\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=config.test_ratio, stratify=y, random_state=config.seed\n    )\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_train, y_train, test_size=config.validation_ratio, stratify=y_train, random_state=config.seed\n    )\n    \n    print(f\"\\nSplit: Train={len(X_train)}, Val={len(X_val)}, Test={len(X_test)}\")\n    \n    # Extract paths and encode\n    paths_text = extract_paths(X_train, y_train, feature_names)\n    bert_embeddings = encode_with_bert(paths_text)\n    \n    # Create datasets\n    train_dataset = SimpleDataset(X_train, y_train)\n    val_dataset = SimpleDataset(X_val, y_val)\n    test_dataset = SimpleDataset(X_test, y_test)\n    \n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=config.batch_size)\n    \n    input_dim = X_train.shape[1]\n    \n    results = {}\n    \n    # Variant 1: WITH BERT\n    print(\"\\n\" + \"=\"*70)\n    print(\"VARIANT 1: WITH BERT STREAM\")\n    print(\"=\"*70)\n    model_with_bert = BERTGBFTFull(input_dim, bert_embeddings)\n    model_with_bert, time_with = train_model(model_with_bert, train_loader, val_loader, \"BERT-GBFT (with BERT)\")\n    results['With BERT'] = evaluate(model_with_bert, test_loader)\n    results['With BERT']['training_time'] = time_with\n    results['With BERT']['parameters'] = count_params(model_with_bert)\n    \n    # Variant 2: WITHOUT BERT\n    print(\"\\n\" + \"=\"*70)\n    print(\"VARIANT 2: WITHOUT BERT STREAM\")\n    print(\"=\"*70)\n    model_without_bert = BERTGBFTNoBERT(input_dim)\n    model_without_bert, time_without = train_model(model_without_bert, train_loader, val_loader, \"BERT-GBFT (no BERT)\")\n    results['Without BERT'] = evaluate(model_without_bert, test_loader)\n    results['Without BERT']['training_time'] = time_without\n    results['Without BERT']['parameters'] = count_params(model_without_bert)\n    \n    # Results\n    print(\"\\n\" + \"=\"*70)\n    print(\"FINAL RESULTS\")\n    print(\"=\"*70)\n    \n    df = pd.DataFrame({\n        name: {\n            'AUC': res['auc'],\n            'F1': res['f1'],\n            'Precision': res['precision'],\n            'Recall': res['recall'],\n            'MCC': res['mcc'],\n            'Parameters': res['parameters'],\n            'Training Time (s)': res['training_time']\n        }\n        for name, res in results.items()\n    }).T\n    \n    print(\"\\n\" + df.to_string())\n    \n    # Analysis\n    with_f1 = results['With BERT']['f1']\n    without_f1 = results['Without BERT']['f1']\n    improvement = ((with_f1 - without_f1) / without_f1) * 100\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"BERT CONTRIBUTION\")\n    print(\"=\"*70)\n    print(f\"\\nWith BERT F1:    {with_f1:.4f}\")\n    print(f\"Without BERT F1: {without_f1:.4f}\")\n    print(f\"\\nImprovement: {improvement:+.2f}%\")\n    \n    if improvement >= 3.0:\n        print(\"\\n✓ BERT provides meaningful improvement (≥3%)\")\n    else:\n        print(f\"\\n✗ BERT improvement below threshold ({improvement:.2f}% < 3%)\")\n    \n    # Plot\n    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n    \n    models = ['With BERT', 'Without BERT']\n    f1_scores = [results[m]['f1'] for m in models]\n    \n    bars = ax.bar(models, f1_scores, color=['#2E86AB', '#E74C3C'], edgecolor='black', linewidth=2)\n    ax.set_ylabel('F1-Score', fontsize=14, fontweight='bold')\n    ax.set_title('Ablation Study: BERT Contribution', fontsize=16, fontweight='bold')\n    ax.set_ylim(min(f1_scores) * 0.95, max(f1_scores) * 1.05)\n    ax.grid(axis='y', alpha=0.3)\n    \n    for bar in bars:\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig(f'{config.output_dir}/ablation_bert_vs_no_bert.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Save\n    df.to_csv(f'{config.output_dir}/ablation_results.csv')\n    print(f\"\\n✓ Results saved to {config.output_dir}/\")\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ABLATION COMPLETED\")\n    print(\"=\"*70)\n    \n    return results\n\nif __name__ == \"__main__\":\n    results = main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-18T21:40:29.535030Z","iopub.execute_input":"2025-11-18T21:40:29.535531Z","iopub.status.idle":"2025-11-18T21:44:28.210270Z","shell.execute_reply.started":"2025-11-18T21:40:29.535479Z","shell.execute_reply":"2025-11-18T21:44:28.208857Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nABLATION STUDY: WITH BERT vs WITHOUT BERT\n======================================================================\n\nLoading Bank Marketing Dataset...\nShape: (45211, 42), Positive: 11.70%\n\nSplit: Train=30742, Val=5426, Test=9043\n\nExtracting decision paths...\nExtracted 30 paths\n\nEncoding with BERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"BERT:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824fa72d7f3f46dbbbd3e8aa1129e190"}},"metadata":{}},{"name":"stdout","text":"BERT embeddings: torch.Size([30, 768])\n\n======================================================================\nVARIANT 1: WITH BERT STREAM\n======================================================================\n\n======================================================================\nTraining: BERT-GBFT (with BERT)\nParameters: 270,562\n======================================================================\nEpoch 10: Loss=0.2065, Val AUC=0.9298\nEpoch 20: Loss=0.1968, Val AUC=0.9336\nEpoch 30: Loss=0.1919, Val AUC=0.9373\nEpoch 40: Loss=0.1849, Val AUC=0.9365\nEpoch 50: Loss=0.1790, Val AUC=0.9353\nBest Val AUC: 0.9379\nTraining time: 124.41s\n\n======================================================================\nVARIANT 2: WITHOUT BERT STREAM\n======================================================================\n\n======================================================================\nTraining: BERT-GBFT (no BERT)\nParameters: 155,106\n======================================================================\nEpoch 10: Loss=0.2061, Val AUC=0.9299\nEpoch 20: Loss=0.1945, Val AUC=0.9363\nEpoch 30: Loss=0.1925, Val AUC=0.9362\nEpoch 40: Loss=0.1850, Val AUC=0.9374\nEarly stopping at epoch 48\nBest Val AUC: 0.9383\nTraining time: 110.94s\n\n======================================================================\nFINAL RESULTS\n======================================================================\n\n                   AUC        F1  Precision    Recall       MCC  Parameters  Training Time (s)\nWith BERT     0.927405  0.620901   0.577705  0.671078  0.568458    270562.0         124.406447\nWithout BERT  0.926136  0.579262   0.612869  0.549149  0.527956    155106.0         110.940171\n\n======================================================================\nBERT CONTRIBUTION\n======================================================================\n\nWith BERT F1:    0.6209\nWithout BERT F1: 0.5793\n\nImprovement: +7.19%\n\n✓ BERT provides meaningful improvement (≥3%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n✓ Results saved to ablation_simple/\n\n======================================================================\nABLATION COMPLETED\n======================================================================\n","output_type":"stream"}],"execution_count":5}]}